{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03342eb2",
   "metadata": {},
   "source": [
    "# MNIST Handwritten Digit Classification\n",
    "\n",
    "This notebook demonstrates a classic classification task using the `clownpiece` library to recognize handwritten digits from the MNIST dataset.\n",
    "\n",
    "We will:\n",
    "1.  Load the MNIST dataset using `torchvision`.\n",
    "2.  Preprocess the data with torch and convert it to `clownpiece` Tensors.\n",
    "3.  Build and train a simple transformer classifier.\n",
    "4.  Use `CrossEntropyLoss` for training.\n",
    "5.  Evaluate the model's accuracy on a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b81bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "from clownpiece import Tensor\n",
    "from clownpiece.autograd import no_grad\n",
    "from clownpiece.nn import Module, Linear, ReLU, Sequential, CrossEntropyLoss, MultiheadAttention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de26fb25",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "\n",
    "To make the code cleaner and more readable, we define two helper functions. `to_CT_tensor` converts a `torch.Tensor` to a `clownpiece.Tensor`, and `to_numpy` converts a `clownpiece.Tensor` back to a `numpy.ndarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fea8b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_CT_tensor(torch_tensor, requires_grad=False):\n",
    "    \"\"\"Converts a torch.Tensor to a clownpiece.Tensor.\"\"\"\n",
    "    return Tensor(torch_tensor.numpy().tolist(), requires_grad=requires_grad)\n",
    "\n",
    "def to_numpy(clownpiece_tensor):\n",
    "    \"\"\"Converts a clownpiece.Tensor to a numpy.ndarray.\"\"\"\n",
    "    return np.array(clownpiece_tensor.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1bfc30",
   "metadata": {},
   "source": [
    "### 1. Loading and Preprocessing the Data\n",
    "\n",
    "We use `torchvision` to load the MNIST dataset. The dataset is transformed into tensors and normalized. We use `torch.utils.data.DataLoader` to create iterators for both the training and test sets, which will feed data to our model in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcf00cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset using torchvision\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "print(\"MNIST dataset loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4fce87",
   "metadata": {},
   "source": [
    "### 2. Defining the Model Architecture\n",
    "\n",
    "Our model is a dummy transformer model, which has \n",
    "1. A image embedding layer that partition the image into patches, and apply the same linear kernel.\n",
    "2. A transformer block\n",
    "3. A reduction operator to squeeze out hidden dimension into singleton\n",
    "4. A final linear projection into classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f592b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "img_dim = 28\n",
    "input_features = img_dim ** 2  # 28x28 images flattened\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "hidden_dim = 4\n",
    "kernel_size = 4\n",
    "\n",
    "num_patches = (img_dim // kernel_size) ** 2\n",
    "\n",
    "class ImageEmbedding(Module):\n",
    "    # split image into (kernel_size x kernel_size) non-interleaving patches and project them to hidden_states\n",
    "    # if you are familiar with LLM but not ViT, consider: \n",
    "    #   patches in CV <=> tokens in NLP \n",
    "    #     num_patches <=> sequence_length\n",
    "    \n",
    "    def __init__(self, img_dim, hidden_dim, kernel_size = 2):\n",
    "        super().__init__()\n",
    "        self.img_dim = img_dim\n",
    "        self.input_features = img_dim ** 2\n",
    "        self.kernel_size = kernel_size\n",
    "        self.patch_size = kernel_size * kernel_size\n",
    "        \n",
    "        assert img_dim % kernel_size == 0, \"image dimensions must be divisible by kernel_size\"\n",
    "        \n",
    "        self.num_patches = (img_dim // kernel_size) ** 2\n",
    "        \n",
    "        self.kernel = Linear(self.patch_size, hidden_dim)\n",
    "\n",
    "    # (batch_size, input_features) -> (batch_size, num_patches, hidden_dim)\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        img_dim = self.img_dim\n",
    "        patch_h, patch_w = self.kernel_size, self.kernel_size\n",
    "        \n",
    "        # Reshape to (batch_size, H, W) to properly extract patches\n",
    "        images = x.reshape([batch_size, img_dim, img_dim])\n",
    "        \n",
    "        # Create patches\n",
    "        # (batch_size, num_patches_h, patch_h, num_patches_w, patch_w)\n",
    "        patches = images.reshape([batch_size, img_dim // patch_h, patch_h, img_dim // patch_w, patch_w])\n",
    "        # Transpose to (batch_size, num_patches_h, num_patches_w, patch_h, patch_w)\n",
    "        patches = patches.transpose(2, 3)\n",
    "        # Reshape to (batch_size, num_patches, patch_size)\n",
    "        patches = patches.reshape([batch_size, self.num_patches, self.patch_size])\n",
    "        \n",
    "        # Project patches to embeddings\n",
    "        return self.kernel(patches)\n",
    "    \n",
    "class TransformerBlock(Module):\n",
    "    # self-attention + mlp\n",
    "    \n",
    "    def __init__(self, hidden_dim, num_heads, ffn_dim):\n",
    "        super().__init__()\n",
    "        self.attention = MultiheadAttention(hidden_dim, num_heads, True)\n",
    "        \n",
    "        self.mlp = Sequential(\n",
    "            Linear(hidden_dim, ffn_dim),\n",
    "            ReLU(),\n",
    "            Linear(ffn_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "        ## hidden dim is too small to use LayerNorm\n",
    "        # self.layer_norm1 = LayerNorm(hidden_dim, affine=False)\n",
    "        # self.layer_norm2 = LayerNorm(hidden_dim, affine=False)\n",
    "\n",
    "    # (batch_size, num_patches, hidden_dim) -> (batch_size, num_patches, hidden_dim)\n",
    "    def forward(self, x):\n",
    "        x = x + self.attention(x)\n",
    "        # x = self.layer_norm1(x)\n",
    "        x = x + self.mlp(x)\n",
    "        # x = self.layer_norm2(x)\n",
    "        return x\n",
    "    \n",
    "class ClampAndReduce(Module): \n",
    "    # reduce hidden_dims by mean pooling\n",
    "    def __init__(self, bound = 2.0):\n",
    "        super().__init__()\n",
    "        self.bound = bound\n",
    "        \n",
    "    # (batch_size, num_patches, hidden_dim) -> (batch_size, num_patches)\n",
    "    def forward(self, x): \n",
    "        x = x.clamp(-self.bound, self.bound) \n",
    "        return x.mean(dim=-1) \n",
    "\n",
    "model = Sequential(\n",
    "    ImageEmbedding(img_dim=img_dim, hidden_dim=hidden_dim, kernel_size=kernel_size),\n",
    "    ReLU(),\n",
    "    TransformerBlock(hidden_dim, num_heads=1, ffn_dim=2*hidden_dim),\n",
    "    ReLU(),\n",
    "    ClampAndReduce(),\n",
    "    Linear(num_patches, num_classes)\n",
    ")\n",
    "\n",
    "print(\"Model Architecture:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6bfb37",
   "metadata": {},
   "source": [
    "### 3. Training the Model\n",
    "\n",
    "Here, we set up the training parameters. We use `CrossEntropyLoss` as our loss function, a fixed `learning_rate` of 0.01, and train for 3 epochs. We'll track the training loss and test accuracy during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dec436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and training parameters\n",
    "loss_fn = CrossEntropyLoss()\n",
    "init_lr = 5e-2\n",
    "grad_clip = 1.0\n",
    "epochs = 5\n",
    "\n",
    "def get_lr(epoch, iter, epochs = epochs, iters_per_epoch = len(train_loader), init_lr = init_lr, final_lr = init_lr / 20):\n",
    "  # exponential lr scheduler\n",
    "  total_iter = epochs * iters_per_epoch\n",
    "  cur_iter = epoch * iters_per_epoch + iter\n",
    "  beta = math.log(final_lr / init_lr) / total_iter\n",
    "  return init_lr * math.exp(beta * cur_iter)\n",
    "\n",
    "train_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "print_iter_interval = 100\n",
    "earily_stop_interval = 5 # * print_iter_interval\n",
    "\n",
    "def earily_stop(acc_history, earily_stop_interval = earily_stop_interval) -> bool:\n",
    "  # return true if accuracy hasn't improved for last earily_stop_interval acc_history\n",
    "  if len(acc_history) <= earily_stop_interval:\n",
    "    return False\n",
    "  max_acc = max(acc_history[:-earily_stop_interval])\n",
    "  return max_acc >= max(acc_history[-earily_stop_interval:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e403e09b",
   "metadata": {},
   "source": [
    "The training loop iterates through the dataset for a specified number of epochs. In each iteration (batch), it performs the following steps:\n",
    "1.  **Forward Pass**: Computes the model's predictions (logits).\n",
    "2.  **Loss Calculation**: Measures the difference between predictions and actual labels.\n",
    "3.  **Backward Pass**: Computes gradients of the loss with respect to model parameters.\n",
    "4.  **Weight Update**: Adjusts model weights using gradient descent.\n",
    "5.  **Zero Gradients**: Resets gradients for the next iteration.\n",
    "\n",
    "> HINT: Model performance may improve slowly or even decrease in first few iterations; do not terminate so eargerly. You may rely on the earily stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d17afd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "# May take up to ~10 minutes\n",
    "def train():\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        print(f\">> Epoch {epoch+1:2}/{epochs}, Lr: {get_lr(epoch, 0):.6f}\")\n",
    "        sum_loss = 0.0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # Flatten the data and convert to clownpiece Tensors\n",
    "            X = to_CT_tensor(data)\n",
    "            y = to_CT_tensor(target, requires_grad=False)\n",
    "\n",
    "            # Forward pass\n",
    "            logits = model(X)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = loss_fn(logits, y)\n",
    "            sum_loss += loss.item()\n",
    "            \n",
    "            if math.isnan(loss.item()):\n",
    "                print(f\"<<Training stopped: NaN loss encountered at epoch {epoch}, batch {batch_idx}.\\n\")\n",
    "                return\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Update weights\n",
    "            with no_grad():\n",
    "                lr = get_lr(epoch, batch_idx)\n",
    "                for param in model.parameters():\n",
    "                    if param.grad is not None:\n",
    "                        grad = param.grad.clamp(-grad_clip, grad_clip)  # Gradient clipping for stability\n",
    "                        param.copy_(param - grad * lr)\n",
    "            \n",
    "            # Zero gradients\n",
    "            for param in model.parameters():\n",
    "                if param.grad is not None:\n",
    "                    param.grad = None\n",
    "            \n",
    "            if batch_idx % print_iter_interval == 0:\n",
    "                avg_loss = sum_loss / (batch_idx + 1)\n",
    "                train_losses.append(avg_loss)\n",
    "                # Evaluation on test set\n",
    "                model.eval()\n",
    "                correct = 0\n",
    "                with no_grad():\n",
    "                    for test_data, test_target in test_loader:\n",
    "                        test_data_flat = test_data.view(test_data.shape[0], -1)\n",
    "                        X_test = to_CT_tensor(test_data_flat)\n",
    "                        \n",
    "                        logits_test = model(X_test)\n",
    "                        pred = np.argmax(to_numpy(logits_test), axis=1)\n",
    "                        correct += np.sum(pred == test_target.numpy())\n",
    "                \n",
    "                accuracy = 100. * correct / len(test_loader.dataset)\n",
    "                test_accuracies.append(accuracy)\n",
    "                \n",
    "                print(f'Train Epoch: {epoch + 1} [{batch_idx * len(data)}/{len(train_loader.dataset)}]\\tLoss: {avg_loss:.6f}, Accuracy: {accuracy:.2f}%', flush=True)\n",
    "                model.train() # Switch back to train mode\n",
    "                \n",
    "                if earily_stop(acc_history=test_accuracies):\n",
    "                    print(f\"<<Training completed: Earily stopped\")\n",
    "                    return\n",
    "                \n",
    "    print(\"<<Training completed: Target epochs reached\")\n",
    "    return\n",
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980ee6cf",
   "metadata": {},
   "source": [
    "### 4. Visualizing the Results\n",
    "\n",
    "Finally, we plot the training loss and test accuracy over the course of training. The x-axis for both plots represents the number of iterations (controlled by `print_iter_interval`), allowing us to see how both metrics evolved as the model processed more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c62597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting results\n",
    "print(f\"Max test accuracy achieved: {max(test_accuracies):.2f}%\")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "ax1.plot(train_losses)\n",
    "ax1.set_title(\"Training Loss\")\n",
    "ax1.set_xlabel(f\"Iterations (x{print_iter_interval})\")\n",
    "ax1.set_ylabel(\"Cross-Entropy Loss\")\n",
    "ax1.set_ylim(0, max(train_losses) * 1.1)  # Set y-axis limit to 10% above max loss\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(test_accuracies)\n",
    "ax2.set_title(\"Test Accuracy\")\n",
    "ax2.set_xlabel(f\"Iterations (x{print_iter_interval})\")\n",
    "ax2.set_ylabel(\"Accuracy (%)\")\n",
    "ax2.set_ylim(0, 100)\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5a66af",
   "metadata": {},
   "source": [
    "##### If everything works correctly, you will get an accuracy of around 85% at the end of epoch 1, and stop around that accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214df6fc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Exploratory Task\n",
    "\n",
    "### A\n",
    "In fact, MNIST is a very simple classifiction task: even simple MLP model (like the one in estate_value_predict) can achieve high accuracy.\n",
    "\n",
    "**Make a copy of this notebook**, then replace the model section to MLP:\n",
    "- decide intermediate dimension size and number of layers; \n",
    "- use a linear layer at last to project hidden states to num_class logits).\n",
    "\n",
    "Try if it acts even better than the dummy transformer model.\n",
    "\n",
    "### B\n",
    "\n",
    "You may wonder why TAs add gradient clipping, test if loss is NaN, and use a small batch size. The numerical stability of this model is prettey bad, and easily explodes.\n",
    "\n",
    "Try to:\n",
    "- change batch size\n",
    "- change learning rate, or remove lr scheduling\n",
    "- change or remove gradient clipping\n",
    "\n",
    "How are their effects on the convergence speed and numerical stability, and which is most sensitive?\n",
    "\n",
    "> These tasks are not graded.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
