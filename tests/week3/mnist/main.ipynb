{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03342eb2",
   "metadata": {},
   "source": [
    "# MNIST Handwritten Digit Classification\n",
    "\n",
    "This notebook demonstrates a classic classification task using the `clownpiece` library to recognize handwritten digits from the MNIST dataset.\n",
    "\n",
    "We will:\n",
    "1.  Load the MNIST dataset using `torchvision`.\n",
    "2.  Preprocess the data and convert it to `clownpiece` Tensors.\n",
    "3.  Build and train a simple MLP classifier.\n",
    "4.  Use `CrossEntropyLoss` for training.\n",
    "5.  Evaluate the model's accuracy on a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b81bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "from clownpiece import Tensor\n",
    "from clownpiece.autograd import no_grad\n",
    "from clownpiece.nn import Module, Linear, ReLU, Sequential, CrossEntropyLoss, MultiheadAttention, LayerNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de26fb25",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "\n",
    "To make the code cleaner and more readable, we define two helper functions. `to_CT_tensor` converts a `torch.Tensor` to a `clownpiece.Tensor`, and `to_numpy` converts a `clownpiece.Tensor` back to a `numpy.ndarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fea8b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_CT_tensor(torch_tensor, requires_grad=False):\n",
    "    \"\"\"Converts a torch.Tensor to a clownpiece.Tensor.\"\"\"\n",
    "    return Tensor(torch_tensor.numpy().tolist(), requires_grad=requires_grad)\n",
    "\n",
    "def to_numpy(clownpiece_tensor):\n",
    "    \"\"\"Converts a clownpiece.Tensor to a numpy.ndarray.\"\"\"\n",
    "    return np.array(clownpiece_tensor.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1bfc30",
   "metadata": {},
   "source": [
    "### 1. Loading and Preprocessing the Data\n",
    "\n",
    "We use `torchvision` to load the MNIST dataset. The dataset is transformed into tensors and normalized. We use `torch.utils.data.DataLoader` to create iterators for both the training and test sets, which will feed data to our model in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcf00cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset using torchvision\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "print(\"MNIST dataset loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4fce87",
   "metadata": {},
   "source": [
    "### 2. Defining the Model Architecture\n",
    "\n",
    "Our model is a simple Multi-Layer Perceptron (MLP) created using the `Sequential` container. It consists of three linear layers with ReLU activation functions in between. The input layer takes flattened 28x28 images (784 features), and the final layer outputs logits for the 10 digit classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f592b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "img_dim = 28\n",
    "input_features = img_dim ** 2  # 28x28 images flattened\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "hidden_dim = 4\n",
    "kernel_size = 4\n",
    "\n",
    "num_patches = (img_dim // kernel_size) ** 2\n",
    "\n",
    "class ImageEmbedding(Module):\n",
    "    # split image into (kernel_size x kernel_size) non-interleaving patches and project them to hidden_states\n",
    "    # if you are familiar with LLM but not ViT, consider: \n",
    "    #   patches in CV <=> tokens in NLP \n",
    "    #     num_patches <=> sequence_length\n",
    "    \n",
    "    def __init__(self, img_dim, hidden_dim, kernel_size = 2):\n",
    "        super().__init__()\n",
    "        self.img_dim = img_dim\n",
    "        self.input_features = img_dim ** 2\n",
    "        self.kernel_size = kernel_size\n",
    "        self.patch_size = kernel_size * kernel_size\n",
    "        \n",
    "        assert img_dim % kernel_size == 0, \"image dimensions must be divisible by kernel_size\"\n",
    "        \n",
    "        self.num_patches = (img_dim // kernel_size) ** 2\n",
    "        \n",
    "        self.kernel = Linear(self.patch_size, hidden_dim)\n",
    "\n",
    "    # (batch_size, input_features) -> (batch_size, num_patches, hidden_dim)\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        img_dim = self.img_dim\n",
    "        patch_h, patch_w = self.kernel_size, self.kernel_size\n",
    "        \n",
    "        # Reshape to (batch_size, H, W) to properly extract patches\n",
    "        images = x.reshape([batch_size, img_dim, img_dim])\n",
    "        \n",
    "        # Create patches\n",
    "        # (batch_size, num_patches_h, patch_h, num_patches_w, patch_w)\n",
    "        patches = images.reshape([batch_size, img_dim // patch_h, patch_h, img_dim // patch_w, patch_w])\n",
    "        # Transpose to (batch_size, num_patches_h, num_patches_w, patch_h, patch_w)\n",
    "        patches = patches.transpose(2, 3)\n",
    "        # Reshape to (batch_size, num_patches, patch_size)\n",
    "        patches = patches.reshape([batch_size, self.num_patches, self.patch_size])\n",
    "        \n",
    "        # Project patches to embeddings\n",
    "        return self.kernel(patches)\n",
    "    \n",
    "class TransformerBlock(Module):\n",
    "    # self-attention + mlp\n",
    "    \n",
    "    def __init__(self, hidden_dim, num_heads, ffn_dim):\n",
    "        super().__init__()\n",
    "        self.attention = MultiheadAttention(hidden_dim, num_heads, True)\n",
    "        \n",
    "        self.mlp = Sequential(\n",
    "            Linear(hidden_dim, ffn_dim),\n",
    "            ReLU(),\n",
    "            Linear(ffn_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "        ## hidden dim is too small to use LayerNorm\n",
    "        # self.layer_norm1 = LayerNorm(hidden_dim, affine=False)\n",
    "        # self.layer_norm2 = LayerNorm(hidden_dim, affine=False)\n",
    "\n",
    "    # (batch_size, num_patches, hidden_dim) -> (batch_size, num_patches, hidden_dim)\n",
    "    def forward(self, x):\n",
    "        x = x + self.attention(x)\n",
    "        # x = self.layer_norm1(x)\n",
    "        x = x + self.mlp(x)\n",
    "        # x = self.layer_norm2(x)\n",
    "        return x\n",
    "    \n",
    "class ClampAndReduce(Module): \n",
    "    # reduce hidden_dims by mean pooling\n",
    "    def __init__(self, bound = 2.0):\n",
    "        super().__init__()\n",
    "        self.bound = bound\n",
    "        \n",
    "    # (batch_size, num_patches, hidden_dim) -> (batch_size, num_patches)\n",
    "    def forward(self, x): \n",
    "        x = x.clamp(-self.bound, self.bound) \n",
    "        return x.mean(dim=-1) \n",
    "\n",
    "model = Sequential(\n",
    "    ImageEmbedding(img_dim=img_dim, hidden_dim=hidden_dim, kernel_size=kernel_size),\n",
    "    ReLU(),\n",
    "    TransformerBlock(hidden_dim, num_heads=1, ffn_dim=2*hidden_dim),\n",
    "    ReLU(),\n",
    "    ClampAndReduce(),\n",
    "    Linear(num_patches, num_classes)\n",
    ")\n",
    "\n",
    "print(\"Model Architecture:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6bfb37",
   "metadata": {},
   "source": [
    "### 3. Training the Model\n",
    "\n",
    "Here, we set up the training parameters. We use `CrossEntropyLoss` as our loss function, a fixed `learning_rate` of 0.01, and train for 3 epochs. We'll track the training loss and test accuracy during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dec436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and training parameters\n",
    "loss_fn = CrossEntropyLoss()\n",
    "init_lr = 5e-2\n",
    "grad_clip = 1.0\n",
    "epochs = 2\n",
    "\n",
    "def get_lr(epoch, iter, epochs = epochs, iters_per_epoch = len(train_loader), init_lr = init_lr, final_lr = init_lr / 20):\n",
    "  # exponential lr scheduler\n",
    "  total_iter = epochs * iters_per_epoch\n",
    "  cur_iter = epoch * iters_per_epoch + iter\n",
    "  beta = math.log(final_lr / init_lr) / total_iter\n",
    "  return init_lr * math.exp(beta * cur_iter)\n",
    "\n",
    "train_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "print_iter_interval = 100\n",
    "earily_stop_interval = 5 # * print_iter_interval\n",
    "\n",
    "def earily_stop(acc_history, earily_stop_interval = earily_stop_interval) -> bool:\n",
    "  # return true if accuracy hasn't improved for last earily_stop_interval acc_history\n",
    "  if len(acc_history) <= earily_stop_interval:\n",
    "    return False\n",
    "  max_acc = max(acc_history[:-earily_stop_interval])\n",
    "  return max_acc >= max(acc_history[-earily_stop_interval:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e403e09b",
   "metadata": {},
   "source": [
    "The training loop iterates through the dataset for a specified number of epochs. In each iteration (batch), it performs the following steps:\n",
    "1.  **Forward Pass**: Computes the model's predictions (logits).\n",
    "2.  **Loss Calculation**: Measures the difference between predictions and actual labels.\n",
    "3.  **Backward Pass**: Computes gradients of the loss with respect to model parameters.\n",
    "4.  **Weight Update**: Adjusts model weights using gradient descent.\n",
    "5.  **Zero Gradients**: Resets gradients for the next iteration.\n",
    "\n",
    "> HINT: Model performance may improve slowly or even decrease in first few iterations; do not terminate so eargerly. You may rely on the earily stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d17afd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "# May take up to ~10 minutes\n",
    "def train():\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        sum_loss = 0.0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # Flatten the data and convert to clownpiece Tensors\n",
    "            data_flat = data.view(data.shape[0], -1)\n",
    "            X = to_CT_tensor(data_flat)\n",
    "            y = to_CT_tensor(target, requires_grad=False)\n",
    "\n",
    "            # Forward pass\n",
    "            logits = model(X)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = loss_fn(logits, y)\n",
    "            sum_loss += loss.item()\n",
    "            \n",
    "            if math.isnan(loss.item()):\n",
    "                print(f\"Training stopped: NaN loss encountered at epoch {epoch}, batch {batch_idx}.\\n\")\n",
    "                return\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Update weights\n",
    "            with no_grad():\n",
    "                lr = get_lr(epoch, batch_idx)\n",
    "                for param in model.parameters():\n",
    "                    if param.grad is not None:\n",
    "                        grad = param.grad.clamp(-grad_clip, grad_clip)  # Gradient clipping for stability\n",
    "                        param.copy_(param - grad * lr)\n",
    "            \n",
    "            # Zero gradients\n",
    "            for param in model.parameters():\n",
    "                if param.grad is not None:\n",
    "                    param.grad = None\n",
    "            \n",
    "            if batch_idx % print_iter_interval == 0:\n",
    "                avg_loss = sum_loss / (batch_idx + 1)\n",
    "                train_losses.append(avg_loss)\n",
    "                # Evaluation on test set\n",
    "                model.eval()\n",
    "                correct = 0\n",
    "                with no_grad():\n",
    "                    for test_data, test_target in test_loader:\n",
    "                        test_data_flat = test_data.view(test_data.shape[0], -1)\n",
    "                        X_test = to_CT_tensor(test_data_flat)\n",
    "                        \n",
    "                        logits_test = model(X_test)\n",
    "                        pred = np.argmax(to_numpy(logits_test), axis=1)\n",
    "                        correct += np.sum(pred == test_target.numpy())\n",
    "                \n",
    "                accuracy = 100. * correct / len(test_loader.dataset)\n",
    "                test_accuracies.append(accuracy)\n",
    "                \n",
    "                print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)}]\\tLoss: {avg_loss:.6f}, Accuracy: {accuracy:.2f}%', flush=True)\n",
    "                model.train() # Switch back to train mode\n",
    "                \n",
    "                if earily_stop(acc_history=test_accuracies):\n",
    "                    print(f\"Training completed: Earily stopped\")\n",
    "                    return\n",
    "                \n",
    "    print(\"Training completed: Target epochs reached\")\n",
    "    return\n",
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980ee6cf",
   "metadata": {},
   "source": [
    "### 4. Visualizing the Results\n",
    "\n",
    "Finally, we plot the training loss and test accuracy over the course of training. The x-axis for both plots represents the number of iterations (controlled by `print_iter_interval`), allowing us to see how both metrics evolved as the model processed more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c62597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "ax1.plot(train_losses)\n",
    "ax1.set_title(\"Training Loss\")\n",
    "ax1.set_xlabel(f\"Iterations (x{print_iter_interval})\")\n",
    "ax1.set_ylabel(\"Cross-Entropy Loss\")\n",
    "ax1.set_ylim(0, max(train_losses) * 1.1)  # Set y-axis limit to 10% above max loss\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(test_accuracies)\n",
    "ax2.set_title(\"Test Accuracy\")\n",
    "ax2.set_xlabel(f\"Iterations (x{print_iter_interval})\")\n",
    "ax2.set_ylabel(\"Accuracy (%)\")\n",
    "ax2.set_ylim(0, 100)\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214df6fc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Exploratory Task\n",
    "\n",
    "### A\n",
    "In fact, MNIST is a very simple classifiction task: even simple MLP model (like the one in estate_value_predict) can achieve high accuracy.\n",
    "\n",
    "**Make a copy of this notebook**, then replace the model section to MLP:\n",
    "- decide intermediate dimension size and number of layers; \n",
    "- use a linear layer at last to project hidden states to num_class logits).\n",
    "\n",
    "Try if it acts even better than the dummy transformer model.\n",
    "\n",
    "### B\n",
    "\n",
    "You may wonder why TAs add gradient clipping, test if loss is NaN, and use a small batch size. The numerical stability of this model is prettey bad, and easily explodes.\n",
    "\n",
    "Try to:\n",
    "- change batch size\n",
    "- change learning rate, or remove lr scheduling\n",
    "- change or remove gradient clipping\n",
    "\n",
    "How are their effects on the convergence speed and numerical stability, and which is most sensitive?\n",
    "\n",
    "> These tasks are not graded.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
